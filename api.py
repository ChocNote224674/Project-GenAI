"""
This module defines a FastAPI application for handling queries, retrieving sources,
and generating AI-powered responses and multiple-choice questions (QCM).
"""

import time
import logging
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from agents import compute_embedding, generate_ai_response, create_mcq
from retrieve import find_best_match
from utils import get_random_qcm
from database import connect_db
from config import TABLE_NAME

# Configure logging
logging.basicConfig(level=logging.INFO)

# Initialize FastAPI
app = FastAPI()

# Model for API requests


class QueryRequest(BaseModel):
    """Model for handling user queries."""
    question: str
    temperature: float = 0.7
    language: str = "english"

# Endpoint to get sources


@app.post("/get_sources")
def get_sources(request: QueryRequest):
    """Finds the best matching source for a given query."""
    start_time = time.time()
    query_embedding = compute_embedding(request.question)
    best_match = find_best_match(request.question, query_embedding)

    response_time = round(time.time() - start_time, 4)
    logging.info("Response time for get_sources: %s seconds", response_time)

    if best_match:
        return best_match
    raise HTTPException(status_code=404, detail="No relevant document found.")

# Endpoint to generate an enriched answer with Gemini


@app.post("/answer")
def answer(request: QueryRequest):
    """Generates an AI response based on the best match or AI-generated content."""
    start_time = time.time()
    query_embedding = compute_embedding(request.question)
    best_match = find_best_match(request.question, query_embedding)

    if not best_match or not best_match.get("answer"):
        llm_response = generate_ai_response(
            request.question, "AI generation", request.language)
        response_time = round(time.time() - start_time, 4)
        logging.info(
            "Response time for answer (no match found): %s seconds",
            response_time)

        return {
            "answer": llm_response,
            "source": "Generated by AI",
            "focus_area": "General Knowledge",
            "similarity": None,
            "metrics": {},
            "response_time": response_time
        }

    response = generate_ai_response(
        request.question,
        best_match["answer"],
        request.language)
    metrics = {
        "cosine_similarity": best_match["cosine_similarity"],
        "jaccard_similarity": best_match["jaccard_similarity"],
        "meteor_score": best_match["meteor_score"],
        "bert_score": best_match["bert_score"],
    }

    response_time = round(time.time() - start_time, 4)
    logging.info(
        "Response time for answer (with match found): %s seconds",
        response_time)
    logging.info("Metrics: %s", metrics)

    return {
        "answer": response,
        "source": best_match["source"],
        "focus_area": best_match["focus_area"],
        "similarity": best_match["cosine_similarity"],
        "metrics": metrics,
        "response_time": response_time
    }


@app.get("/qcm/themes")
def get_themes():
    """Returns a list of available QCM themes."""
    conn = connect_db()
    cursor = conn.cursor()
    cursor.execute(f"SELECT DISTINCT focus_area FROM {TABLE_NAME}")
    themes = [row[0] for row in cursor.fetchall()]
    cursor.close()
    conn.close()
    return {"themes": themes}


@app.get("/qcm")
def get_qcm(n: int = 5, focus_area: str = None):
    """Returns a set of dynamically generated multiple-choice questions filtered by theme."""
    questions = get_random_qcm(n, focus_area)
    mcq_list = [create_mcq(q[0], q[1], q[2]) for q in questions]
    return {"questions": mcq_list}
